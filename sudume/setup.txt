## 1. NVIDIA ドライバのインストール
sudo apt update
sudo apt install -y nvidia-driver-535  # 535以上の最新バージョンを推奨

# インストール後、再起動が必要です
sudo reboot

# 再起動後、ドライバの確認
nvidia-smi

## 2. CUDA Toolkitのインストール
# 最新の安定版CUDA 12.3をダウンロードしてインストール
wget https://developer.download.nvidia.com/compute/cuda/12.3.2/local_installers/cuda_12.3.2_545.23.08_linux.run
sudo sh cuda_12.3.2_545.23.08_linux.run --silent --toolkit
rm cuda_12.3.2_545.23.08_linux.run

## 3. 環境変数の設定
# CUDA関連の環境変数を設定
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

## 4. PyAudioの依存関係インストール
sudo apt install -y portaudio19-dev python3-dev

## 5. Ollama GPU版のインストール
curl -fsSL https://ollama.com/install.sh | sh

# インストール確認
ollama --version

## 6. VOICEVOX Engineのインストール (GPU対応版)
sudo apt install -y nodejs npm python3-pip

# 最新版VOICEVOXをダウンロード
wget https://github.com/VOICEVOX/voicevox_engine/releases/download/0.14.10/voicevox_engine-linux-nvidia-0.14.10.tar.gz
tar -xzf voicevox_engine-linux-nvidia-0.14.10.tar.gz
rm voicevox_engine-linux-nvidia-0.14.10.tar.gz
mv voicevox_engine-linux-nvidia-0.14.10 ~/voicevox_engine

## 7. Python環境のセットアップ
# 仮想環境を作成
python3 -m venv ~/pumpkin_venv
source ~/pumpkin_venv/bin/activate

# 必要なパッケージをインストール
pip install numpy scipy sounddevice SpeechRecognition pyaudio requests torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121

## 8. パンプキントークリポジトリのセットアップ
mkdir -p ~/pumpkin_talk
cd ~/pumpkin_talk

# ここにgpu.pyとpumpkin_config.jsonファイルを配置

## 9. 実行用シェルスクリプトの作成
# 以下の内容で~/start_pumpkin.shを作成してください

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
#!/bin/bash

# GPU-Check
if ! command -v nvidia-smi &> /dev/null; then
    echo "NVIDIAドライバが見つかりません。環境を確認してください。"
    exit 1
fi

# モデルダウンロード（初回のみ）
if ! ollama list | grep -q "qwen2.5:1.5b"; then
    echo "Qwen 1.5Bモデルをダウンロード中..."
    ollama pull qwen2.5:1.5b
fi

if ! ollama list | grep -q "gemma2:2b-instruct-jp"; then
    echo "Gemma2 (日本語)モデルをダウンロード中..."
    ollama pull gemma2:2b-instruct-jp
fi

# VOICEVOX Engineを起動
cd ~/voicevox_engine
./run.sh --use_gpu &
VOICEVOX_PID=$!

echo "VOICEVOX Engineを起動しました (PID: $VOICEVOX_PID)"
echo "VOICEVOXサーバーの起動を待っています..."
# サービスが起動するまで待機
for i in {1..10}; do
    if curl -s http://localhost:50021/version > /dev/null; then
        echo "VOICEVOX準備完了"
        break
    fi
    echo "待機中... ($i/10)"
    sleep 2
done

# Ollamaサーバーの起動確認
echo "Ollamaサーバーの起動を確認しています..."
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "Ollamaサーバーを起動しています..."
    ollama serve &
    OLLAMA_PID=$!
    # 起動待ち
    for i in {1..10}; do
        if curl -s http://localhost:11434/api/tags > /dev/null; then
            echo "Ollama準備完了"
            break
        fi
        echo "Ollama待機中... ($i/10)"
        sleep 2
    done
else
    echo "Ollamaサーバーは既に実行中です"
    OLLAMA_PID=""
fi

# パンプキントークを起動
cd ~/pumpkin_talk
source ~/pumpkin_venv/bin/activate
echo "パンプキントークを起動します..."
python gpu.py

# 終了時にVOICEVOXとOllamaも終了
echo "パンプキントークを終了しました。関連サービスをクリーンアップしています..."
if [ -n "$VOICEVOX_PID" ]; then
    kill $VOICEVOX_PID
    echo "VOICEVOX Engineを終了しました"
fi

if [ -n "$OLLAMA_PID" ]; then
    kill $OLLAMA_PID
    echo "Ollamaサーバーを終了しました"
fi

echo "すべての処理が完了しました"
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""


# スクリプトに実行権限を付与
chmod +x ~/start_pumpkin.sh

## 10. アプリケーションの実行
# 以下のコマンドでパンプキントークを起動します
~/start_pumpkin.sh

## 注意事項
- 初回起動時はモデルのダウンロードが必要なため、少し時間がかかります
- GPUメモリ使用量を確認するには nvidia-smi コマンドを使用してください
- 必要に応じて pumpkin_config.json 内の設定を調整して性能を最適化できます
- スパコン環境では、バックグラウンドプロセスとしての実行が推奨されます
- 実行時のGPUメモリ要件: 約4-6GB (モデルサイズによる)